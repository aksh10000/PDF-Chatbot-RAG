{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --no-cache-dir transformers==4.28.1 datasets==2.11.0 torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install langchain==0.0.184\n!pip install PyPDF2==3.0.1\n!pip install python-dotenv==1.0.0\n!pip install streamlit==1.18.1\n # openai==0.27.6\n!pip install faiss-cpu==1.7.4\n!pip install altair==4\n!pip install tiktoken==0.4.0\n!pip install huggingface-hub==0.14.1 \n!pip install InstructorEmbedding==1.0.1 \n!pip install sentence-transformers==2.2.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import streamlit as st\nfrom dotenv import load_dotenv\nfrom PyPDF2 import PdfReader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.chains import ConversationalRetrievalChain\nfrom htmlTemplates import css, bot_template, user_template\nfrom langchain.llms import HuggingFaceHub\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom langchain import HuggingFacePipeline\nfrom sentence_transformers import SentenceTransformer\n\ndef get_pdf_text(pdf_docs):\n    text = \"\"\n    for pdf in pdf_docs:\n        pdf_reader = PdfReader(pdf)\n        for page in pdf_reader.pages:\n            text += page.extract_text()\n    return text\n\n\ndef get_text_chunks(text):\n    text_splitter = CharacterTextSplitter(\n        separator=\"\\n\",\n        chunk_size=1000,\n        chunk_overlap=200,\n        length_function=len\n    )\n    chunks = text_splitter.split_text(text)\n    return chunks\n\n\ndef get_vectorstore(text_chunks):\n#     embeddings = OpenAIEmbeddings()\n    embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n    return vectorstore\n\n\ndef get_conversation_chain(vectorstore):\n#     llm = ChatOpenAI()\n    model_name = \"google/flan-t5-base\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n    llm = HuggingFacePipeline.from_model_and_tokenizer(model=model, tokenizer=tokenizer)\n    memory = ConversationBufferMemory(\n        memory_key='chat_history', return_messages=True)\n    conversation_chain = ConversationalRetrievalChain.from_llm(\n        llm=llm,\n        retriever=vectorstore.as_retriever(),\n        memory=memory\n    )\n    return conversation_chain\n\n\ndef user_input(user_question):\n    response = st.session_state.conversation({'question': user_question})\n    st.session_state.chat_history = response['chat_history']\n\n    for i, message in enumerate(st.session_state.chat_history):\n        if i % 2 == 0:\n            st.write(user_template.replace(\n                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n        else:\n            st.write(bot_template.replace(\n                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n\n\ndef main():\n    load_dotenv()\n    st.set_page_config(page_title=\"AI CHAT AGENT\",\n                       page_icon=\":books:\")\n    st.write(css, unsafe_allow_html=True)\n\n    if \"conversation\" not in st.session_state:\n        st.session_state.conversation = None\n    if \"chat_history\" not in st.session_state:\n        st.session_state.chat_history = None\n\n    st.header(\"Chat using PDFs :books:\")\n    user_question = st.text_input(\"What would you like to know?:\")\n    if user_question:\n        user_input(user_question)\n\n    with st.sidebar:\n        st.subheader(\"Your documents\")\n        pdf_docs = st.file_uploader(\n            \"Upload your PDFs here and click on 'Process'\", accept_multiple_files=True)\n        if st.button(\"Process\"):\n            with st.spinner(\"Processing\"):\n                #pdf text\n                raw_text = get_pdf_text(pdf_docs)\n\n                #text chunks\n                text_chunks = get_text_chunks(raw_text)\n\n                #vector store for storing\n                vectorstore = get_vectorstore(text_chunks)\n\n                #conversation chain\n                st.session_state.conversation = get_conversation_chain(\n                    vectorstore)\n\n\nif __name__ == '__main__':\n    main()\n    \n##Only to run in cloud jupyter notebook, else run on local computer without this:\n# time.sleep(1)\n# HTML(open('streamlit-magic.html', encoding='utf-8').read())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Only to run in cloud jupyter notebook, else run on local computer without this:\n# %%streamlit\n# # %streamlit is a \"cell magic\" command\n# from app import *","metadata":{},"execution_count":null,"outputs":[]}]}